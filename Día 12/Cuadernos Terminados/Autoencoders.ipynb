{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7eb627e2",
   "metadata": {},
   "source": [
    "# Autoencoders\n",
    "\n",
    "Los **Autoencoders** son otro algoritmo de aprendizaje automático que corresponde a los modelos de **Aprendizaje No Supervisado**, y que vamos a aprender ya mismo.\n",
    "\n",
    "Los **Autoencoders** son una herramienta muy poderosa, diseñada para aprender representaciones eficientes de los datos. La máquina va a aprender a representar los datos de manera eficiente, y te aseguro que ya vas a ver a qué me refiero.\n",
    "\n",
    "Un Autoencoder básicamente lo que hace es intentar **aprender una función que comprime los datos que recibe**, reduciéndolos a una representación codificada de dimensión mucho menor, y **luego los reconstruye** de vuelta a su forma original o una aproximación cercana a ella.\n",
    "\n",
    "Para decirlo en palabras muy simples, imagina que tienes un dibujo gigante, pero quieres guardarlo en tu bolsillo. Un autoencoder mira tu dibujo, descubre los puntos más importantes, y luego hace una versión miniatura de él. Después, cuando quieras ver tu dibujo otra vez en tamaño normal, el autoencoder puede recrearlo casi perfecto en su tamaño original, a paetir de una fórmula que ha utilizado para comprimirlo y descomprimirlo.\n",
    "\n",
    "\n",
    "### ¿Para qué sirve un autoencoder?\n",
    "\n",
    "Básicamente, ayuda a guardar cosas grandes en espacios pequeñitos.\n",
    "\n",
    "\n",
    "### Aplicación práctica\n",
    "\n",
    "Antes de poner en práctica los **Autoencoders** vamos a necesitar trabajar con una librería de python llamada **tensorflow**, que a diferencia de todas las librerías con las que hemos estado trabajando hasta el momento, no ha sido instalada en tu ordenador cuando instalaste anaconda, por lo tanto no puedes importarla aún.\n",
    "\n",
    "Para eso, te comparto [este otro cuaderno](Instalar%20tensorflow.ipynb), que contiene el código para **instalar tensorflow** en tu ordenador. Antes de avanzar con este práctica, simplemente ábrelo y ejecuta su contenido. Solo tendrás que hacer esto una vez en tu computadora, y luego ya podrás importar **tensorflow** en cualquier cuaderno Jupyter en el que quieras utilizarlo.\n",
    "\n",
    "\n",
    "Ahora sí, comencemos **importando todas las librerías** que necesitaremos para este ejercicio, que son varias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ad07cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97a20be5",
   "metadata": {},
   "source": [
    "Ahora vamos a llamar a un dataset muy interesante que se llama `digits`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed59ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digitos = load_digits()\n",
    "digitos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e89cdc2",
   "metadata": {},
   "source": [
    "Y digo que este dataset es interesante porque lo que contiene es información que sirve para construir imágenes.\n",
    "\n",
    "Iris es un diccionario que contiene, entre otras cosas, una clave `data`, cuyo valor es una colección de arrays, que contiene **1797 imágenes de 8 pixels de ancho por 8 pixels de alto**. En realidad lo que tiene son arrays de dos dimensiones cuyo contenido son números que representan el valor de gris de cada pixel, por lo que podemos usar esa información para crear **mapas de bits** que forman imágenes.\n",
    "\n",
    "Veamos un ejemplo, tomemos el índice `0` de esta base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8f6e8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digitos['data'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6dff595d",
   "metadata": {},
   "source": [
    "Aquí vemos que cada índice de `digits['data']` contiene un **array de 64 elementos**. Ahora probemos visualizar estos números pero con el formato de **8 por 8**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b363ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digitos['data'][0].reshape(8, 8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8046def",
   "metadata": {},
   "source": [
    "Aquí ya nos va comenzando a quedar un poco más claro a qué nos referimos con **mapa de bits**.\n",
    "\n",
    "Cada elemento del array representa un bit de una imagen, y su valor dice qué tan claro debe ser el bit que representa.\n",
    "\n",
    "Y ahora la magia: vamos a representar esto con matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78b9013c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2245be63490>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digitos['data'][0].reshape(8, 8))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04fe6f6b",
   "metadata": {},
   "source": [
    "Y ahí lo tienes. Nuestra imagen es el dibujo a mano del número `0`.\n",
    "\n",
    "Eso es lo que contiene esta base de datos llamada `digits`: 1797 imágenes de 8 bits que representan dígitos escritos a mano.\n",
    "\n",
    "Haz tu miso el intento de cambiar el índice `[0]` por el número que quieras entre **0** y **1797** para ver los diferentes números.\n",
    "\n",
    "Incluso te voy a mostrar un truco que lo hace más simple. `digits` trae una función llamada `images()` que nos permite seleccionar a nuestros dígitos mucho más fácilmente, pero no te la enseñé al comienzo para que puedas entender mejor la lógica que subyace en la estructura de `digits`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "effdbbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digitos.images[4]);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b47bf3e",
   "metadata": {},
   "source": [
    "Muy bien, ahora que conoces el dataset con el que estamos trabajando, veamos cómo aplicar los **Autoencoders** en este caso.\n",
    "\n",
    "Vamos a necesitar una variable `X` (mayúscula) que contenga todas las imágenes de dígitos que hay en el dataset. Para eso vamos a recurrir a la función `data` que nos brinda `digits`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a25532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digitos.data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a06ade15",
   "metadata": {},
   "source": [
    "En este caso no vamos a necesitar una variable `y`, así que directamente no la creamos.\n",
    "\n",
    "El siguiente paso es **normalizar nuestros números**. Recuerda que normalizar valores significa asegurarnos que todos comienzan y terminan dentro del mismo rango numérico. En este caso podemos hacerlo así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a529ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 16.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a63c095",
   "metadata": {},
   "source": [
    "¿Por qué los normalizo de esta manera? Porque típicamente los números de `digits` tienen valores en el rango de **0** a **16** para cada píxel. Al dividir cada número por `0.16` me aseguro de que su valor termine estando entre **0** y **1**, sin afectar la precisión de las relaciones de valor que hay entre ellos. Básicamente es como reducir la escala de un mapa.\n",
    "\n",
    "La normalización es un paso esencial en este caso porque así facilitamos el proceso de entrenamiento de la red neuronal. Podríamos no hacerlo, pero normalizar los datos ayuda a prevenir problemas numéricos durante el entrenamiento, como el desbordamiento de números, y generalmente permite que el algoritmo converja más rápidamente hacia una solución.\n",
    "\n",
    "Con nuestros datos normalizados, vamos a dividirlos entre **entrenamiento** y **prueba**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d42a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_entrena, X_prueba = train_test_split(X, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2355cc4",
   "metadata": {},
   "source": [
    "Ahora viene la parte desafiante, que es construir el **autoecoder** usando `keras`, que es el modelo que importamos al comienzo del cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b012fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagen_entrada = Input(shape=(64, ))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0882523b",
   "metadata": {},
   "source": [
    "Aquí estoy creando una variable que contiene la función `Input` (con **I** mayúscula), que no es el `input` (con **i** minúscula) que hemos usado hasta ahora para pedirle al usuario que ingrese algo, sino la función `Input` de `keras.layers` que hemos importado al comienzo del cuaderno desde `tensorflow`.\n",
    "\n",
    "Este `Input` se utiliza para instanciar una nueva capa de entrada, que llamamos ***capa tensorial***. Básicamente es la forma específica que el modelo va a esperar que tengan nuestros datos. Y aquí le estamos diciendo, que nuestros arrays de 8 por 8 van a ser pasados de manera aplanada, en un array de una sola dimensión, que va a tener 64 elementos. Este es el punto de partida para construir un modelo de red neuronal.\n",
    "\n",
    "Ahora vamos a crear la variable `codificado`, que va a contener una red neuronal. Aquí las cosas pueden ponerse algo abstractas, así que las explicaré en detalle.\n",
    "\n",
    "Primero escribiré la línea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fac6a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "codificado = Dense(32, activation='relu') (imagen_entrada)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f4c34c8",
   "metadata": {},
   "source": [
    "Esta variable `codificado` va a contener una **capa densa**. ¿Qué significa esto? Significa que va a ser una capa que va a contener muchos puntos de información, y que todos esos puntos van a estar conectados entre sí, como una red de neuronas donde cada neurona tiene una conexión directa con cada una de las demás neuronas. Se llama **densa** porque al ser una red con tantas conexiones, va a ser una red con una gran densidad.\n",
    "\n",
    "Entonces para eso hemos usado `Dense` (que también es la función que importamos desde `keras` al comienzo del cuaderno), que es la función que se encarga de crear esa capa desde cero. El primer argumento que nos pide es el *número de nodos*, o de neuronas que va a tener nuestra red, y que se van a conectar todas entre sí. Yo he puesto `32`, como un punto de partida ilustrativo, pero no es un estándar fijo ni la única opción posible. Lo he elegido en este caso porque es la mitad de **64 pixels** por imagen.\n",
    "\n",
    "La elección del número de neuronas en una capa de una red neuronal depende de varios factores y objetivos específicos del modelo y del conjunto de datos con el que estás trabajando. La decisión sobre cuántas neuronas utilizar puede influir en la capacidad del modelo para aprender patrones complejos en los datos:\n",
    "+ Tener un número grande de neuronas puede aumentar la capacidad del modelo para aprender detalles finos de los datos de entrenamiento, lo que podría ser beneficioso si tu conjunto de datos es complejo y variado. Sin embargo, también aumenta el riesgo de que el modelo aprenda tanto, que aprende hasta el \"ruido\" en los datos de entrenamiento en lugar de las relaciones importantes generales, lo que puede perjudicar su rendimiento en datos nuevos.\n",
    "+ Y por otro lado, si eliges un número muy pequeño de neuronas, el modelo podría no tener suficiente capacidad para aprender adecuadamente los patrones en los datos, lo que crearía un modelo demasiado simple que es incapaz de capturar la estructura subyacente de los datos.\n",
    "\t\n",
    "En este caso la elección de `32` como el número de neuronas en el ejemplo es un balance entre estas consideraciones, proporcionando una cantidad moderada de capacidad de aprendizaje sin ser excesivamente compleja para un conjunto de datos relativamente simple como los dígitos manuscritos. Sin embargo, es completamente válido que experimentes con este número para encontrar el mejor rendimiento para tu tarea específica.\n",
    "\n",
    "Sigamos analizando la función `Dense`. El siguiente argumento es `activation`, al que he establecido como `'relu'`. Aquí estoy especificando cuál va a ser la función de activación que usaremos en esta capa. `relu` se refiere *'Rectified Linear Unit'*, que es una de las funciones de activación más comunes en las redes neuronales debido a su simplicidad y eficacia.\n",
    "\n",
    "Y finalmente `(imagen_entrada)` es la parte donde le indicamos a `Dense` que la capa densa que hemos definido, debe aplicarse a las entradas proporcionadas por `imagen_entrada`. \n",
    "\n",
    "Entonces ya tenemos nuestra capa `codificado`, que es una **capa densamente codificada**, ¿y qué objetivo va a cumplir esta capa? Bueno, imagina que tienes un grupo de amigos y les quieres pasar un mensaje a cada uno de ellos. En una capa densa, cada amigo representa una \"neurona\" o un punto donde puede ocurrir algo interesante con el mensaje. En este caso 32 amigos. Ahora, imagina que decides no solo pasar tu mensaje original a cada uno, sino que, basado en lo que sabes de cada amigo, modificas un poco el mensaje para cada uno. Quizás a algunos les añades un chiste porque sabes que les gusta reír, o a otros les haces el mensaje más corto porque prefieren las cosas directas.\n",
    "\n",
    "Una capa densa en una red neuronal hace algo similar con la información que recibe. Piénsala como una capa llena de amigos (neuronas) donde cada uno recibe el mensaje (datos de entrada), y cada uno lo modifica un poco basado en sus propias \"reglas\" antes de pasarlo. Debido a que en una capa densa, cada neurona está conectada a todas las entradas, cada conexión puede pensar en el mensaje de manera diferente, añadiendo su propio giro único basado en cómo se haya entrenado la red.\n",
    "\n",
    "Así que, en términos simples, una capa densa es **un grupo de neuronas trabajando juntas**, donde cada una contribuye un poco basada en su propio peso, para formar un nuevo mensaje (que es la salida de la capa) que combina todos sus puntos de vista.\n",
    "\n",
    "Avancemos. Ahora que hemos construido el **codificador**, vamos a construir el **decodificador**. Porque todo lo que ha sido codificado necesita poder decodificarse en algún momento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18fe3bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "decodificado = Dense(64, activation='sigmoid') (codificado)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f65dba7",
   "metadata": {},
   "source": [
    "Entonces hemos usado la misma función `Dense`, pero esta vez le hemos dicho que queremos `64` nodos, que es un numero que generalmente va a ser igual a los puntos de entrada originales (que en nuestro caso eran **64 pixels**), y le he pedido que se use la función de activación `sigmoid` en esta capa, que es una función que convierte los valores de entrada a la capa en valores entre **0** y **1**, lo que es muy útil ya que los datos de entrada originalmente también estaban en este rango.\n",
    "\n",
    "Y finalmente le hemos pedido que la capa `Dense` se aplique a la salida de la capa que codificación que creamos recién y que se llama `codificado`.\n",
    "\n",
    "Pero aquí no termina todo. Esta ha sido la **preparación de los datos** y la **creación del codificador y del decodificador**. Ahora toca crear el **autoeconder** en sí mismo. Aquí es donde llamamos al algoritmo que queremos aplicar en esta lección:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11c8b6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(imagen_entrada, decodificado)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0b86d9d",
   "metadata": {},
   "source": [
    "Y vamos a preparar el modelo de `autoencoder` para el **entrenamiento**, especificando cómo se debería actualizar durante el aprendizaje y cómo se medirá su rendimiento.\n",
    "\n",
    "Vamos a usar la función `compile()` que es un método que prepara el modelo para el entrenamiento, dándole detalles cruciales sobre cómo debe aprender de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b943694",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam',\n",
    "                   loss='binary_crossentropy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c873b3c",
   "metadata": {},
   "source": [
    "¿Qué son esos parámetros en la función `compile()`?\n",
    "+ `optimizer='adam'`: El optimizador es el algoritmo que ajusta los pesos del modelo. `'Adam'` es uno de los optimizadores más populares y efectivos porque ajusta la tasa de aprendizaje automáticamente y funciona bien en la mayoría de los casos sin mucha configuración.\n",
    "+ `loss='binary_crossentropy'`: La función de pérdida (`loss`) mide qué tan bien el modelo está haciendo su trabajo, en este caso, reconstruyendo la entrada original a partir de la versión comprimida. `'Binary_crossentropy'` es una elección común cuando los datos de entrada son valores binarios o en el rango de **0** a **1**, porque esta función de pérdida compara cada píxel de la imagen de entrada con el píxel correspondiente de la imagen reconstruida.\n",
    "\n",
    "En resumen, esta línea le dice al modelo que use el optimizador `adam` para ajustar sus pesos y minimizar la diferencia entre las entradas originales y las reconstruidas, medida por la función de pérdida de **entropía cruzada binaria**, durante el entrenamiento. \n",
    "\n",
    "Muy bien, con nuestro modelo de **autoencoder** configurado, ha llegado el momento de entrenarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df176485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.6969 - val_loss: 0.6786\n",
      "Epoch 2/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6743 - val_loss: 0.6566\n",
      "Epoch 3/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6518 - val_loss: 0.6336\n",
      "Epoch 4/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6282 - val_loss: 0.6081\n",
      "Epoch 5/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6017 - val_loss: 0.5798\n",
      "Epoch 6/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5729 - val_loss: 0.5504\n",
      "Epoch 7/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5431 - val_loss: 0.5217\n",
      "Epoch 8/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5147 - val_loss: 0.4958\n",
      "Epoch 9/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4898 - val_loss: 0.4740\n",
      "Epoch 10/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4696 - val_loss: 0.4568\n",
      "Epoch 11/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4525 - val_loss: 0.4433\n",
      "Epoch 12/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4392 - val_loss: 0.4329\n",
      "Epoch 13/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4306 - val_loss: 0.4243\n",
      "Epoch 14/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4211 - val_loss: 0.4171\n",
      "Epoch 15/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4143 - val_loss: 0.4109\n",
      "Epoch 16/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4084 - val_loss: 0.4053\n",
      "Epoch 17/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4032 - val_loss: 0.4005\n",
      "Epoch 18/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3987 - val_loss: 0.3961\n",
      "Epoch 19/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3938 - val_loss: 0.3918\n",
      "Epoch 20/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3911 - val_loss: 0.3878\n",
      "Epoch 21/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3860 - val_loss: 0.3837\n",
      "Epoch 22/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3811 - val_loss: 0.3796\n",
      "Epoch 23/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3769 - val_loss: 0.3758\n",
      "Epoch 24/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3736 - val_loss: 0.3719\n",
      "Epoch 25/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3690 - val_loss: 0.3682\n",
      "Epoch 26/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3654 - val_loss: 0.3647\n",
      "Epoch 27/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3621 - val_loss: 0.3613\n",
      "Epoch 28/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3570 - val_loss: 0.3581\n",
      "Epoch 29/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3545 - val_loss: 0.3550\n",
      "Epoch 30/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3521 - val_loss: 0.3521\n",
      "Epoch 31/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3482 - val_loss: 0.3492\n",
      "Epoch 32/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3461 - val_loss: 0.3465\n",
      "Epoch 33/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3437 - val_loss: 0.3439\n",
      "Epoch 34/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3393 - val_loss: 0.3415\n",
      "Epoch 35/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3368 - val_loss: 0.3390\n",
      "Epoch 36/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3345 - val_loss: 0.3367\n",
      "Epoch 37/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3330 - val_loss: 0.3346\n",
      "Epoch 38/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3303 - val_loss: 0.3325\n",
      "Epoch 39/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3287 - val_loss: 0.3305\n",
      "Epoch 40/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3260 - val_loss: 0.3285\n",
      "Epoch 41/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3245 - val_loss: 0.3267\n",
      "Epoch 42/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3241 - val_loss: 0.3249\n",
      "Epoch 43/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3208 - val_loss: 0.3232\n",
      "Epoch 44/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3188 - val_loss: 0.3214\n",
      "Epoch 45/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3171 - val_loss: 0.3198\n",
      "Epoch 46/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3146 - val_loss: 0.3182\n",
      "Epoch 47/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3135 - val_loss: 0.3167\n",
      "Epoch 48/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3114 - val_loss: 0.3151\n",
      "Epoch 49/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3113 - val_loss: 0.3137\n",
      "Epoch 50/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3094 - val_loss: 0.3123\n",
      "Epoch 51/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3059 - val_loss: 0.3109\n",
      "Epoch 52/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3071 - val_loss: 0.3096\n",
      "Epoch 53/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3049 - val_loss: 0.3083\n",
      "Epoch 54/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3043 - val_loss: 0.3070\n",
      "Epoch 55/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3027 - val_loss: 0.3058\n",
      "Epoch 56/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3009 - val_loss: 0.3047\n",
      "Epoch 57/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3005 - val_loss: 0.3035\n",
      "Epoch 58/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2992 - val_loss: 0.3024\n",
      "Epoch 59/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2972 - val_loss: 0.3013\n",
      "Epoch 60/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2966 - val_loss: 0.3003\n",
      "Epoch 61/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2955 - val_loss: 0.2993\n",
      "Epoch 62/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2946 - val_loss: 0.2983\n",
      "Epoch 63/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2939 - val_loss: 0.2972\n",
      "Epoch 64/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2927 - val_loss: 0.2963\n",
      "Epoch 65/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2936 - val_loss: 0.2954\n",
      "Epoch 66/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2909 - val_loss: 0.2945\n",
      "Epoch 67/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2901 - val_loss: 0.2936\n",
      "Epoch 68/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2900 - val_loss: 0.2928\n",
      "Epoch 69/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2889 - val_loss: 0.2919\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2877 - val_loss: 0.2911\n",
      "Epoch 71/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2873 - val_loss: 0.2903\n",
      "Epoch 72/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2868 - val_loss: 0.2895\n",
      "Epoch 73/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2854 - val_loss: 0.2887\n",
      "Epoch 74/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2840 - val_loss: 0.2880\n",
      "Epoch 75/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2850 - val_loss: 0.2872\n",
      "Epoch 76/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2831 - val_loss: 0.2865\n",
      "Epoch 77/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2829 - val_loss: 0.2858\n",
      "Epoch 78/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2822 - val_loss: 0.2851\n",
      "Epoch 79/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2811 - val_loss: 0.2844\n",
      "Epoch 80/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2803 - val_loss: 0.2837\n",
      "Epoch 81/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2797 - val_loss: 0.2830\n",
      "Epoch 82/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2795 - val_loss: 0.2824\n",
      "Epoch 83/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2790 - val_loss: 0.2818\n",
      "Epoch 84/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2782 - val_loss: 0.2812\n",
      "Epoch 85/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2771 - val_loss: 0.2805\n",
      "Epoch 86/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2766 - val_loss: 0.2800\n",
      "Epoch 87/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2768 - val_loss: 0.2794\n",
      "Epoch 88/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2769 - val_loss: 0.2788\n",
      "Epoch 89/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2752 - val_loss: 0.2782\n",
      "Epoch 90/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2746 - val_loss: 0.2777\n",
      "Epoch 91/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2746 - val_loss: 0.2772\n",
      "Epoch 92/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2739 - val_loss: 0.2767\n",
      "Epoch 93/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2722 - val_loss: 0.2762\n",
      "Epoch 94/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2728 - val_loss: 0.2757\n",
      "Epoch 95/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2729 - val_loss: 0.2752\n",
      "Epoch 96/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2714 - val_loss: 0.2747\n",
      "Epoch 97/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2708 - val_loss: 0.2743\n",
      "Epoch 98/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2703 - val_loss: 0.2738\n",
      "Epoch 99/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2705 - val_loss: 0.2734\n",
      "Epoch 100/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2693 - val_loss: 0.2729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2245c7e5590>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_entrena,\n",
    "               X_entrena,\n",
    "               epochs=100,\n",
    "               batch_size=256,\n",
    "               shuffle=True,\n",
    "               validation_data=(X_prueba, X_prueba))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa2a7494",
   "metadata": {},
   "source": [
    "Permíteme explicarte los parámetros que he usado en la función anterior:\n",
    "+ `X_entrena`: Hemos usado el mismo conjunto de datos tanto para las **entradas** como para las **salidas esperadas** porque el objetivo es aprender a reconstruir las entradas originales a partir de las representaciones comprimidas.\n",
    "+ `epochs=100`: Es el número de veces que repasará todo el conjunto de datos de entrenamiento.\n",
    "+ `batch_size=256`: Durante el entrenamiento, los datos se dividen en pequeños paquetes o \"lotes\" que se procesan de forma independiente. `batch_size=256` indica que el modelo debería tomar **256** ejemplos de `X_entrena` a la vez, procesarlos, actualizar sus pesos y luego pasar al siguiente lote de 256 ejemplos. El uso de lotes ayuda a hacer el entrenamiento más eficiente. La elección de `256` como tamaño del lote es una decisión basada en la experiencia práctica, y funciona como un punto de partida razonable. Puedes modificarlo por supuesto.\n",
    "+ `shuffle=True`: Los datos se deben mezclar antes de cada `epoch`. Esto ayuda a prevenir que el modelo aprenda el orden de los datos en lugar de las características subyacentes, mejorando aún más la generalización.\n",
    "+ `validation_data`: Además de entrenar el modelo, también queremos monitorear su desempeño en un conjunto de datos que no ha visto durante el entrenamiento.\n",
    "\n",
    "Entonces este bloque de código inicia el proceso de **entrenamiento del autoencoder**, y lo alimenta con datos de entrenamiento, diciéndole cuántas veces repasar esos datos, cómo agruparlos y en qué orden, y cómo comprobar que está aprendiendo correctamente usando un conjunto de prueba.\n",
    "\n",
    "Al ejecutarlo podemos ver cómo va repitiendo el proceso en cada uno de los **100 epochs** que le hemos pedido que realice.\n",
    "\n",
    "Y ahora sí, tenemos un modelo que ha encontrado la forma de codificar nuestras imágenes para que nos entren en el bolsillo, y también es capaz de decodificarlas para volver a representarlas.\n",
    "\n",
    "Entonces vamos con el último paso, que es **visualizar nuestros resultados**.\n",
    "\n",
    "Vamos a crear un bloque de código que tome **10 imágenes** del dataset, que las muestre cómo son inicialmente, y que las vuelva a representar luego de codificarlas y decodificarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d989e5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    plt.subplot(2,\n",
    "               10,\n",
    "               i + 1)\n",
    "    plt.imshow(X_prueba[i].reshape(8, 8))\n",
    "    \n",
    "    plt.subplot(2,\n",
    "               10,\n",
    "               i + 1 + 10)\n",
    "    plt.imshow(autoencoder.predict(X_prueba)[i].reshape(8, 8));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40b6df12",
   "metadata": {},
   "source": [
    "Con esto podemos ver la comparación de las imágenes antes y después de ser decodificadas, donde vemos que el resultado es prácticamente igual, con algunas pequeñas diferencias producto de todo el proceso, pero que aún así nos devuelve una imagen bastante fiel.\n",
    "\n",
    "Esta ha sido una lección extensa, pero que creo que ha valido mucho la pena, así como la lección que sigue, que espero que no te la pierdas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fca220b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
